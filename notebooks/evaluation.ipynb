{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c026f472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is set: True\n",
      "Length: 164\n",
      "Prefix: sk-proj...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(\"OPENAI_API_KEY is set:\", bool(key))\n",
    "print(\"Length:\", len(key) if key else None)\n",
    "print(\"Prefix:\", key[:7] + \"...\" if key else None)  # optional: shows only first chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c32f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.genai import make_judge  # preferred in newer MLflow :contentReference[oaicite:2]{index=2}\n",
    "\n",
    "gt_judge = make_judge(\n",
    "    name=\"xr_config_quality_score\",\n",
    "    instructions=(\n",
    "        \"You are grading an IOS XR telemetry configuration.\\n\\n\"\n",
    "        \"User request (inputs): {{ inputs }}\\n\\n\"\n",
    "        \"Candidate config (outputs): {{ outputs }}\\n\\n\"\n",
    "        \"Reference acceptable config (expectations): {{ expectations }}\\n\\n\"\n",
    "        \"Score quality from 0.0 to 1.0.\\n\"\n",
    "        \"Hard requirements (must match): IP, port, transport (grpc no-tls), encoding.\\n\"\n",
    "        \"Be lenient about names, ordering, and sample-interval unless requested.\\n\"\n",
    "        \"Penalize only if sensor-paths are clearly unrelated.\\n\"\n",
    "        \"Do NOT output telemetry config. Do NOT output code. Keep any explanation extremely short.\"\n",
    "    ),\n",
    "    feedback_value_type=float,\n",
    "    model=\"openai:/gpt-4.1-mini\",\n",
    "    inference_params={\"temperature\": 0, \"max_tokens\": 300},  # <-- was 10 (too small)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dae8bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RunCfg:\n",
    "    vector_db: str\n",
    "    top_k: int\n",
    "    filter_fields: Dict[str, Any]\n",
    "    temperature: float\n",
    "    model_chat: str\n",
    "    model_embed: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525669bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,\n",
       " RunCfg(vector_db='fixed_window_embeddings', top_k=5, filter_fields={}, temperature=0, model_chat='gpt-4.1-nano', model_embed='text-embedding-3-small'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_grid(vector_dbs, top_ks, filters, temps, chat_models, embed_models):\n",
    "    cfgs = []\n",
    "    for vdb in vector_dbs:\n",
    "        for k in top_ks:\n",
    "            for ff in filters:\n",
    "                for t in temps:\n",
    "                    for cm in chat_models:\n",
    "                        for em in embed_models:\n",
    "                            cfgs.append(RunCfg(vdb, k, ff, t, cm, em))\n",
    "    return cfgs\n",
    "\n",
    "VECTOR_DBS = [\"fixed_window_embeddings\", \"catalog_embeddings_improved\"]  # add your 3rd\n",
    "TOP_KS = [5, 10]\n",
    "FILTERS = [{}]  # adjust to your payload schema,  {\"protocol_tag\": \"bgp\"}\n",
    "TEMPS = [0,0.1]\n",
    "CHAT_MODELS = [\"gpt-4.1-nano\", \"gpt-4.1-mini\"]\n",
    "EMBED_MODELS = [\"text-embedding-3-small\"]\n",
    "\n",
    "cfgs = make_grid(VECTOR_DBS, TOP_KS, FILTERS, TEMPS, CHAT_MODELS, EMBED_MODELS)\n",
    "len(cfgs), cfgs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5739fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path.cwd().resolve().parents[0]  # repo root if cwd==repo/notebooks\n",
    "sys.path.insert(0, str(ROOT / \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0b15d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported tracerag modules OK.\n"
     ]
    }
   ],
   "source": [
    "from tracerag.rag.naive import naive_rag, build_openai_chat_fn\n",
    "from tracerag.retrieval.qdrant import (\n",
    "    QdrantRetrievalConfig,\n",
    "    build_openai_embedding_fn,\n",
    "    build_qdrant_retriever,\n",
    ")\n",
    "\n",
    "print(\"Imported tracerag modules OK.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0e2e1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class RunCfg:\n",
    "    vector_db: str                 # we'll map this to a Qdrant collection (or backend)\n",
    "    top_k: int\n",
    "    filter_fields: Dict[str, Any]  # e.g., {\"domain\":\"bgp\"} or {}\n",
    "    temperature: float\n",
    "    model_chat: str\n",
    "    model_embed: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f921b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models as qmodels\n",
    "\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6b15f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_qdrant_filter(filter_fields: Dict[str, Any]) -> Optional[qmodels.Filter]:\n",
    "    if not filter_fields:\n",
    "        return None\n",
    "\n",
    "    must: List[qmodels.FieldCondition] = []\n",
    "    for key, value in filter_fields.items():\n",
    "        must.append(\n",
    "            qmodels.FieldCondition(\n",
    "                key=key,\n",
    "                match=qmodels.MatchValue(value=value),\n",
    "            )\n",
    "        )\n",
    "    return qmodels.Filter(must=must)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dcb15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_retriever(\n",
    "    *,\n",
    "    cfg: RunCfg,\n",
    "    qdrant: QdrantClient,\n",
    "    openai_client: OpenAI,\n",
    "):\n",
    "    embed_fn = build_openai_embedding_fn(openai_client, model=cfg.model_embed)\n",
    "\n",
    "    q_filter = build_qdrant_filter(cfg.filter_fields)\n",
    "\n",
    "    config = QdrantRetrievalConfig(\n",
    "        collection_name=cfg.vector_db,  # <-- mapping: vector_db -> collection\n",
    "        top_k=cfg.top_k,\n",
    "        query_filter=q_filter,\n",
    "    )\n",
    "\n",
    "    qdrant_retriever = build_qdrant_retriever(\n",
    "        qdrant=qdrant,\n",
    "        embedding_fn=embed_fn,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # Return a function: retriever(query, k) -> List[Chunk]\n",
    "    # Keep filter fixed per cfg (since filter_fields is a variation)\n",
    "    return lambda query, k: qdrant_retriever(query, top_k=k, query_filter=q_filter)\n",
    "\n",
    "\n",
    "def make_chat_fn(cfg: RunCfg, openai_client: OpenAI):\n",
    "    return build_openai_chat_fn(\n",
    "        openai_client,\n",
    "        model=cfg.model_chat,\n",
    "        temperature=cfg.temperature,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "692acef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt length: 1573\n",
      "You are a Cisco IOS XR network engineer generating IOS XR 7.x model-driven telemetry configuration.\n",
      "\n",
      "INPUTS:\n",
      "- USER_REQUEST: describes the intent (e.g., “BGP telemetry”), destination IP/port, and optionally interval.\n",
      "- CONTEXT: a list of valid YANG sensor-path candidates.\n",
      "\n",
      "HARD RULES:\n",
      "- Output ONLY \n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT_PATH = Path(\"../data/iosxr_prompt.txt\")  # <-- your file\n",
    "SYSTEM_PROMPT = SYSTEM_PROMPT_PATH.read_text(encoding=\"utf-8\")\n",
    "\n",
    "print(\"System prompt length:\", len(SYSTEM_PROMPT))\n",
    "print(SYSTEM_PROMPT[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c4dbb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_predict_one(prompt: str, cfg: RunCfg, qdrant, openai_client) -> str:\n",
    "    retriever = make_retriever(cfg=cfg, qdrant=qdrant, openai_client=openai_client)\n",
    "    chat_fn = make_chat_fn(cfg, openai_client=openai_client)\n",
    "\n",
    "    resp = naive_rag(\n",
    "        user_query=prompt,\n",
    "        retriever=retriever,\n",
    "        chat_fn=chat_fn,\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        top_k=cfg.top_k,\n",
    "        answer_instruction=\"Return only IOS XR telemetry configuration.\",\n",
    "    )\n",
    "    return resp.answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ddb08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_eval_data(dataset_rows, cfg: RunCfg, qdrant, openai_client, max_examples=None):\n",
    "    n = len(dataset_rows) if max_examples is None else min(len(dataset_rows), max_examples)\n",
    "    eval_data = []\n",
    "\n",
    "    for i in range(n):\n",
    "        prompt = dataset_rows[i][\"prompt\"]\n",
    "        reference = dataset_rows[i][\"completion\"]\n",
    "\n",
    "        candidate = rag_predict_one(prompt, cfg, qdrant, openai_client)\n",
    "\n",
    "\n",
    "#         eval_data.append({\n",
    "#     \"inputs\": {\"prompt\": prompt},\n",
    "#     \"outputs\": {\"response\": candidate},           # <-- change here\n",
    "#     \"expectations\": {\"expected_response\": reference},\n",
    "# })\n",
    "    eval_data.append({\n",
    "        \"inputs\": {\"prompt\": prompt},\n",
    "        \"outputs\": {\"response\": candidate},\n",
    "        \"expectations\": {\"expected_response\": reference},\n",
    "    })\n",
    "\n",
    "    return eval_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c288a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import mlflow\n",
    "\n",
    "# def run_one_cfg_mlflow(cfg: RunCfg, dataset_rows, qdrant, openai_client, max_examples=None):\n",
    "#     # log only your 6 variations\n",
    "#     mlflow.log_params({\n",
    "#         \"vector_db\": cfg.vector_db,\n",
    "#         \"top_k\": cfg.top_k,\n",
    "#         \"filter_fields\": json.dumps(cfg.filter_fields, sort_keys=True),\n",
    "#         \"temperature\": cfg.temperature,\n",
    "#         \"model_chat\": cfg.model_chat,\n",
    "#         \"model_embed\": cfg.model_embed,\n",
    "#     })\n",
    "\n",
    "#     eval_data = build_eval_data(dataset_rows, cfg, qdrant, openai_client, max_examples=max_examples)\n",
    "\n",
    "#     # MLflow judge\n",
    "#     results = mlflow.genai.evaluate(\n",
    "#         data=eval_data,\n",
    "#         scorers=[gt_judge],\n",
    "#     )\n",
    "\n",
    "#     # results.metrics usually contains aggregate metrics; but easiest is to also compute pass rate from the table\n",
    "#     # MLflow returns an EvaluationResult with a \"tables\" field in many setups.\n",
    "#     # We'll be defensive and compute ourselves:\n",
    "#     # Each row's result is stored in results.tables[\"evaluation_results\"] or similar depending on version.\n",
    "#     return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b648bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Any, Dict, Iterable, List, Optional\n",
    "\n",
    "def traces_to_eval_df(traces) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert MLflow GenAI traces into a flat per-example evaluation DataFrame.\n",
    "\n",
    "    Expected to work across MLflow versions where:\n",
    "      - traces may be a list[dict] or a DataFrame\n",
    "      - request / response payload shapes may vary slightly\n",
    "      - judge results live under `assessments`\n",
    "\n",
    "    Output columns:\n",
    "      - trace_id\n",
    "      - prompt\n",
    "      - candidate\n",
    "      - expected\n",
    "      - score\n",
    "      - rationale\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize input to DataFrame\n",
    "    tdf = traces if isinstance(traces, pd.DataFrame) else pd.DataFrame(traces)\n",
    "\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "\n",
    "    for _, r in tdf.iterrows():\n",
    "        trace_id = r.get(\"trace_id\")\n",
    "\n",
    "        # ---------- request ----------\n",
    "        # Common shapes:\n",
    "        #   {\"inputs\": {\"prompt\": \"...\"}}\n",
    "        #   {\"prompt\": \"...\"}\n",
    "        req = r.get(\"request\") or {}\n",
    "        prompt = None\n",
    "        if isinstance(req, dict):\n",
    "            prompt = (\n",
    "                (req.get(\"inputs\") or {}).get(\"prompt\")\n",
    "                or req.get(\"prompt\")\n",
    "            )\n",
    "\n",
    "        # ---------- response ----------\n",
    "        # Common shapes:\n",
    "        #   {\"outputs\": {\"response\": \"...\"}}\n",
    "        #   {\"response\": \"...\"}\n",
    "        resp = r.get(\"response\") or {}\n",
    "        candidate = None\n",
    "        if isinstance(resp, dict):\n",
    "            candidate = (\n",
    "                (resp.get(\"outputs\") or {}).get(\"response\")\n",
    "                or resp.get(\"response\")\n",
    "            )\n",
    "\n",
    "        # ---------- assessments ----------\n",
    "        score = None\n",
    "        rationale = None\n",
    "        expected = None\n",
    "\n",
    "        assessments = r.get(\"assessments\") or []\n",
    "        for a in assessments:\n",
    "            name = a.get(\"assessment_name\")\n",
    "\n",
    "            # Your LLM judge\n",
    "            if name == \"xr_config_quality_score\":\n",
    "                fb = a.get(\"feedback\") or {}\n",
    "                score = fb.get(\"value\")\n",
    "                rationale = a.get(\"rationale\")\n",
    "\n",
    "            # Reference / expectation (if present)\n",
    "            elif name in (\"expected_response\", \"expectation\"):\n",
    "                exp = a.get(\"expectation\") or {}\n",
    "                expected = exp.get(\"value\")\n",
    "\n",
    "        rows.append({\n",
    "            \"trace_id\": trace_id,\n",
    "            \"prompt\": prompt,\n",
    "            \"candidate\": candidate,\n",
    "            \"expected\": expected,\n",
    "            \"score\": score,\n",
    "            \"rationale\": rationale,\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # Normalize numeric score\n",
    "    if \"score\" in df.columns:\n",
    "        df[\"score\"] = pd.to_numeric(df[\"score\"], errors=\"coerce\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6638c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import mlflow\n",
    "\n",
    "def run_one_cfg_mlflow(cfg: RunCfg, dataset_rows, qdrant, openai_client, max_examples=None):\n",
    "    mlflow.log_params({\n",
    "        \"vector_db\": cfg.vector_db,\n",
    "        \"top_k\": cfg.top_k,\n",
    "        \"filter_fields\": json.dumps(cfg.filter_fields, sort_keys=True),\n",
    "        \"temperature\": cfg.temperature,\n",
    "        \"model_chat\": cfg.model_chat,\n",
    "        \"model_embed\": cfg.model_embed,\n",
    "    })\n",
    "\n",
    "    eval_data = build_eval_data(dataset_rows, cfg, qdrant, openai_client, max_examples=max_examples)\n",
    "\n",
    "    results = mlflow.genai.evaluate(\n",
    "        data=eval_data,\n",
    "        scorers=[gt_judge],\n",
    "    )\n",
    "\n",
    "    # --- link traces to this run (super useful) ---\n",
    "    eval_run_id = results.run_id\n",
    "    mlflow.set_tag(\"eval_run_id\", eval_run_id)\n",
    "\n",
    "    # --- OPTIONAL but highly recommended: aggregate metrics + per-example CSV ---\n",
    "    # Pull traces and compute aggregates\n",
    "    traces = mlflow.search_traces(run_id=eval_run_id)\n",
    "    df = traces_to_eval_df(traces)  # your helper that extracts score, prompt, etc.\n",
    "\n",
    "    # aggregate metrics visible in MLflow UI\n",
    "    mlflow.log_metric(\"judge_mean\", float(df[\"score\"].mean()))\n",
    "    mlflow.log_metric(\"judge_min\", float(df[\"score\"].min()))\n",
    "    mlflow.log_metric(\"judge_pass_rate_ge_0.8\", float((df[\"score\"] >= 0.8).mean()))\n",
    "    mlflow.log_metric(\"n_examples\", int(df[\"score\"].notna().sum()))\n",
    "\n",
    "    # store per-example evidence with the run\n",
    "    per_example_csv = \"per_example_eval.csv\"\n",
    "    df.to_csv(per_example_csv, index=False)\n",
    "    mlflow.log_artifact(per_example_csv)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c41832f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 100\n",
      "Example keys: dict_keys(['prompt', 'completion'])\n",
      "Prompt preview:\n",
      " Generate Cisco IOS XR 7.0.1 telemetry configuration to monitor L2VPN xconnect/pseudowire operational state. Use gRPC with no TLS. Telemetry server address is 192.0.2.110 with port 57500. Choose releva\n",
      "Completion preview:\n",
      " telemetry model-driven\n",
      " sensor-group L2VPN-XCONNECT-OPER\n",
      " sensor-path Cisco-IOS-XR-l2vpn-oper:l2vpnv2/active/xconnects\n",
      " sensor-path Cisco-IOS-XR-l2vpn-oper:l2vpnv2/active/pseudowires\n",
      " sensor-path Cisc\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = Path(\"../data/judge_dataset.jsonl\")  # <-- change if needed\n",
    "\n",
    "def load_jsonl(path: Path) -> List[Dict[str, Any]]:\n",
    "    rows = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "dataset = load_jsonl(DATASET_PATH)\n",
    "print(\"Loaded rows:\", len(dataset))\n",
    "print(\"Example keys:\", dataset[0].keys())\n",
    "print(\"Prompt preview:\\n\", dataset[0][\"prompt\"][:200])\n",
    "print(\"Completion preview:\\n\", dataset[0][\"completion\"][:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4486fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e536420",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "dataset = random.sample(dataset, 3)  # smaller subset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "657009a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musel/Documents/github/TRACE/.venv/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from openai import OpenAI\n",
    "\n",
    "mlflow.set_tracking_uri(\"file://\" + str((Path.cwd() / \"mlruns\").resolve()))\n",
    "mlflow.set_experiment(\"xr_rag_variations_judged\")\n",
    "\n",
    "qdrant = QdrantClient(host=\"localhost\", port=6333)\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b43aa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/musel/Documents/github/TRACE/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026/01/12 14:23:35 INFO mlflow.models.evaluation.utils.trace: Auto tracing is temporarily enabled during the model evaluation for computing some metrics and debugging. To disable tracing, call `mlflow.autolog(disable=True)`.\n",
      "Evaluating:   0%|          | 0/1 [Elapsed: 00:00, Remaining: ?] /home/musel/Documents/github/TRACE/.venv/lib/python3.11/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 6: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='{\"result...: None}, annotations=[]), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...ider_specific_fields={}), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:03, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mfixed_window_embeddings|k=5|t=0|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94m18cb5ef8356f4dacb33b67a107c8eca3\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: fixed_window_embeddings|k=5|t=0|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:03, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mfixed_window_embeddings|k=5|t=0|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94md669bf1b41cf4f40bb13e058bf3499b0\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: fixed_window_embeddings|k=5|t=0|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:02, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mfixed_window_embeddings|k=5|t=0.1|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94mce4f6d58c540423e8795fa3b25667b47\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: fixed_window_embeddings|k=5|t=0.1|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:02, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mfixed_window_embeddings|k=5|t=0.1|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94mbcbaee67810f4217a528ebaec30844a6\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: fixed_window_embeddings|k=5|t=0.1|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:03, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mfixed_window_embeddings|k=10|t=0|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94m710022e351a9416689fdb2caaa6b9c65\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: fixed_window_embeddings|k=10|t=0|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:02, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mfixed_window_embeddings|k=10|t=0|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94m28f883389a9d49b88970381d117fa0b9\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: fixed_window_embeddings|k=10|t=0|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:01, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mfixed_window_embeddings|k=10|t=0.1|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94mbb421cb136a9419dac96ab9dad4773a3\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: fixed_window_embeddings|k=10|t=0.1|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:02, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mfixed_window_embeddings|k=10|t=0.1|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94ma875d90a04864508b0d17aac8be6314d\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: fixed_window_embeddings|k=10|t=0.1|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:02, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mcatalog_embeddings_improved|k=5|t=0|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94mc836e611154b4e8a85458e340be3d41a\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: catalog_embeddings_improved|k=5|t=0|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:01, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mcatalog_embeddings_improved|k=5|t=0|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94m84d8209bf2e54f9299e81506ca261717\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: catalog_embeddings_improved|k=5|t=0|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:02, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mcatalog_embeddings_improved|k=5|t=0.1|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94mb0d064e44a374e99a8b4a8c8991eee01\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: catalog_embeddings_improved|k=5|t=0.1|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:02, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mcatalog_embeddings_improved|k=5|t=0.1|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94m2219c82078004fa7a0fd8f62cef1fb2e\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: catalog_embeddings_improved|k=5|t=0.1|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:03, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mcatalog_embeddings_improved|k=10|t=0|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94mbffb9dd96e6648fea4d8f1b0c3679bbe\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: catalog_embeddings_improved|k=10|t=0|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:02, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mcatalog_embeddings_improved|k=10|t=0|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94m7f9b7da5842f4e4eb09dd036812ca780\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: catalog_embeddings_improved|k=10|t=0|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:02, Remaining: 00:00] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mcatalog_embeddings_improved|k=10|t=0.1|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94m35953649af624151a5cd4d7ffcb30afd\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: catalog_embeddings_improved|k=10|t=0.1|chat=gpt-4.1-nano|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [Elapsed: 00:01, Remaining: 00:00] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✨ Evaluation completed.\n",
      "\n",
      "Metrics and evaluation results are logged to the MLflow run:\n",
      "  Run name: \u001b[94mcatalog_embeddings_improved|k=10|t=0.1|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\u001b[0m\n",
      "  Run ID: \u001b[94m752947195729418a9fad1657fbb13858\u001b[0m\n",
      "\n",
      "To view the detailed evaluation results with sample-wise scores,\n",
      "open the \u001b[93m\u001b[1mTraces\u001b[0m tab in the Run page in the MLflow UI.\n",
      "\n",
      "DONE: catalog_embeddings_improved|k=10|t=0.1|chat=gpt-4.1-mini|emb=text-embedding-3-small|f={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"parent_sweep\") as parent:\n",
    "    for cfg in cfgs:\n",
    "        run_name = f\"{cfg.vector_db}|k={cfg.top_k}|t={cfg.temperature}|chat={cfg.model_chat}|emb={cfg.model_embed}|f={cfg.filter_fields}\"\n",
    "        with mlflow.start_run(run_name=run_name, nested=True):\n",
    "            results = run_one_cfg_mlflow(\n",
    "                cfg=cfg,\n",
    "                dataset_rows=dataset,\n",
    "                qdrant=qdrant,\n",
    "                openai_client=openai_client,\n",
    "                max_examples=50,   # start small for iteration; remove later\n",
    "            )\n",
    "            print(\"DONE:\", run_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4173d613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>params.vector_db</th>\n",
       "      <th>params.top_k</th>\n",
       "      <th>params.temperature</th>\n",
       "      <th>params.model_chat</th>\n",
       "      <th>params.model_embed</th>\n",
       "      <th>params.filter_fields</th>\n",
       "      <th>metrics.judge_mean</th>\n",
       "      <th>metrics.judge_pass_rate_ge_0.8</th>\n",
       "      <th>metrics.judge_min</th>\n",
       "      <th>metrics.n_examples</th>\n",
       "      <th>tags.eval_run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ce4f6d58c540423e8795fa3b25667b47</td>\n",
       "      <td>fixed_window_embeddings|k=5|t=0.1|chat=gpt-4.1...</td>\n",
       "      <td>fixed_window_embeddings</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ce4f6d58c540423e8795fa3b25667b47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>d669bf1b41cf4f40bb13e058bf3499b0</td>\n",
       "      <td>fixed_window_embeddings|k=5|t=0|chat=gpt-4.1-m...</td>\n",
       "      <td>fixed_window_embeddings</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>d669bf1b41cf4f40bb13e058bf3499b0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bb421cb136a9419dac96ab9dad4773a3</td>\n",
       "      <td>fixed_window_embeddings|k=10|t=0.1|chat=gpt-4....</td>\n",
       "      <td>fixed_window_embeddings</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bb421cb136a9419dac96ab9dad4773a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18cb5ef8356f4dacb33b67a107c8eca3</td>\n",
       "      <td>fixed_window_embeddings|k=5|t=0|chat=gpt-4.1-n...</td>\n",
       "      <td>fixed_window_embeddings</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18cb5ef8356f4dacb33b67a107c8eca3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a875d90a04864508b0d17aac8be6314d</td>\n",
       "      <td>fixed_window_embeddings|k=10|t=0.1|chat=gpt-4....</td>\n",
       "      <td>fixed_window_embeddings</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a875d90a04864508b0d17aac8be6314d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>752947195729418a9fad1657fbb13858</td>\n",
       "      <td>catalog_embeddings_improved|k=10|t=0.1|chat=gp...</td>\n",
       "      <td>catalog_embeddings_improved</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>752947195729418a9fad1657fbb13858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bffb9dd96e6648fea4d8f1b0c3679bbe</td>\n",
       "      <td>catalog_embeddings_improved|k=10|t=0|chat=gpt-...</td>\n",
       "      <td>catalog_embeddings_improved</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bffb9dd96e6648fea4d8f1b0c3679bbe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7f9b7da5842f4e4eb09dd036812ca780</td>\n",
       "      <td>catalog_embeddings_improved|k=10|t=0|chat=gpt-...</td>\n",
       "      <td>catalog_embeddings_improved</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7f9b7da5842f4e4eb09dd036812ca780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2219c82078004fa7a0fd8f62cef1fb2e</td>\n",
       "      <td>catalog_embeddings_improved|k=5|t=0.1|chat=gpt...</td>\n",
       "      <td>catalog_embeddings_improved</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>gpt-4.1-mini</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2219c82078004fa7a0fd8f62cef1fb2e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c836e611154b4e8a85458e340be3d41a</td>\n",
       "      <td>catalog_embeddings_improved|k=5|t=0|chat=gpt-4...</td>\n",
       "      <td>catalog_embeddings_improved</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4.1-nano</td>\n",
       "      <td>text-embedding-3-small</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>c836e611154b4e8a85458e340be3d41a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              run_id  \\\n",
       "13  ce4f6d58c540423e8795fa3b25667b47   \n",
       "14  d669bf1b41cf4f40bb13e058bf3499b0   \n",
       "9   bb421cb136a9419dac96ab9dad4773a3   \n",
       "15  18cb5ef8356f4dacb33b67a107c8eca3   \n",
       "8   a875d90a04864508b0d17aac8be6314d   \n",
       "0   752947195729418a9fad1657fbb13858   \n",
       "3   bffb9dd96e6648fea4d8f1b0c3679bbe   \n",
       "2   7f9b7da5842f4e4eb09dd036812ca780   \n",
       "4   2219c82078004fa7a0fd8f62cef1fb2e   \n",
       "7   c836e611154b4e8a85458e340be3d41a   \n",
       "\n",
       "                                  tags.mlflow.runName  \\\n",
       "13  fixed_window_embeddings|k=5|t=0.1|chat=gpt-4.1...   \n",
       "14  fixed_window_embeddings|k=5|t=0|chat=gpt-4.1-m...   \n",
       "9   fixed_window_embeddings|k=10|t=0.1|chat=gpt-4....   \n",
       "15  fixed_window_embeddings|k=5|t=0|chat=gpt-4.1-n...   \n",
       "8   fixed_window_embeddings|k=10|t=0.1|chat=gpt-4....   \n",
       "0   catalog_embeddings_improved|k=10|t=0.1|chat=gp...   \n",
       "3   catalog_embeddings_improved|k=10|t=0|chat=gpt-...   \n",
       "2   catalog_embeddings_improved|k=10|t=0|chat=gpt-...   \n",
       "4   catalog_embeddings_improved|k=5|t=0.1|chat=gpt...   \n",
       "7   catalog_embeddings_improved|k=5|t=0|chat=gpt-4...   \n",
       "\n",
       "               params.vector_db params.top_k params.temperature  \\\n",
       "13      fixed_window_embeddings            5                0.1   \n",
       "14      fixed_window_embeddings            5                  0   \n",
       "9       fixed_window_embeddings           10                0.1   \n",
       "15      fixed_window_embeddings            5                  0   \n",
       "8       fixed_window_embeddings           10                0.1   \n",
       "0   catalog_embeddings_improved           10                0.1   \n",
       "3   catalog_embeddings_improved           10                  0   \n",
       "2   catalog_embeddings_improved           10                  0   \n",
       "4   catalog_embeddings_improved            5                0.1   \n",
       "7   catalog_embeddings_improved            5                  0   \n",
       "\n",
       "   params.model_chat      params.model_embed params.filter_fields  \\\n",
       "13      gpt-4.1-nano  text-embedding-3-small                   {}   \n",
       "14      gpt-4.1-mini  text-embedding-3-small                   {}   \n",
       "9       gpt-4.1-nano  text-embedding-3-small                   {}   \n",
       "15      gpt-4.1-nano  text-embedding-3-small                   {}   \n",
       "8       gpt-4.1-mini  text-embedding-3-small                   {}   \n",
       "0       gpt-4.1-mini  text-embedding-3-small                   {}   \n",
       "3       gpt-4.1-nano  text-embedding-3-small                   {}   \n",
       "2       gpt-4.1-mini  text-embedding-3-small                   {}   \n",
       "4       gpt-4.1-mini  text-embedding-3-small                   {}   \n",
       "7       gpt-4.1-nano  text-embedding-3-small                   {}   \n",
       "\n",
       "    metrics.judge_mean  metrics.judge_pass_rate_ge_0.8  metrics.judge_min  \\\n",
       "13                 0.7                             0.0                0.7   \n",
       "14                 0.7                             0.0                0.7   \n",
       "9                  0.7                             0.0                0.7   \n",
       "15                 0.7                             0.0                0.7   \n",
       "8                  0.7                             0.0                0.7   \n",
       "0                  0.6                             0.0                0.6   \n",
       "3                  0.6                             0.0                0.6   \n",
       "2                  0.6                             0.0                0.6   \n",
       "4                  0.6                             0.0                0.6   \n",
       "7                  0.6                             0.0                0.6   \n",
       "\n",
       "    metrics.n_examples                  tags.eval_run_id  \n",
       "13                 1.0  ce4f6d58c540423e8795fa3b25667b47  \n",
       "14                 1.0  d669bf1b41cf4f40bb13e058bf3499b0  \n",
       "9                  1.0  bb421cb136a9419dac96ab9dad4773a3  \n",
       "15                 1.0  18cb5ef8356f4dacb33b67a107c8eca3  \n",
       "8                  1.0  a875d90a04864508b0d17aac8be6314d  \n",
       "0                  1.0  752947195729418a9fad1657fbb13858  \n",
       "3                  1.0  bffb9dd96e6648fea4d8f1b0c3679bbe  \n",
       "2                  1.0  7f9b7da5842f4e4eb09dd036812ca780  \n",
       "4                  1.0  2219c82078004fa7a0fd8f62cef1fb2e  \n",
       "7                  1.0  c836e611154b4e8a85458e340be3d41a  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "exp = mlflow.get_experiment_by_name(\"xr_rag_variations_judged\")\n",
    "\n",
    "runs_df = mlflow.search_runs(\n",
    "    experiment_ids=[exp.experiment_id],\n",
    "    output_format=\"pandas\",\n",
    ")\n",
    "\n",
    "# Keep child runs only (exclude parent by name)\n",
    "child = runs_df[runs_df[\"tags.mlflow.runName\"] != \"parent_sweep\"].copy()\n",
    "\n",
    "cols = [\n",
    "    \"run_id\",\n",
    "    \"tags.mlflow.runName\",\n",
    "    \"params.vector_db\",\n",
    "    \"params.top_k\",\n",
    "    \"params.temperature\",\n",
    "    \"params.model_chat\",\n",
    "    \"params.model_embed\",\n",
    "    \"params.filter_fields\",\n",
    "    \"metrics.judge_mean\",\n",
    "    \"metrics.judge_pass_rate_ge_0.8\",\n",
    "    \"metrics.judge_min\",\n",
    "    \"metrics.n_examples\",\n",
    "    \"tags.eval_run_id\",\n",
    "]\n",
    "leaderboard = child[[c for c in cols if c in child.columns]].copy()\n",
    "leaderboard = leaderboard.sort_values(\"metrics.judge_mean\", ascending=False)\n",
    "\n",
    "leaderboard.to_csv(\"sweep_leaderboard.csv\", index=False)\n",
    "leaderboard.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e2d98fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(leaderboard[\"params.top_k\"].astype(float),\n",
    "            leaderboard[\"metrics.judge_mean\"].astype(float))\n",
    "plt.xlabel(\"top_k\")\n",
    "plt.ylabel(\"judge_mean\")\n",
    "plt.title(\"Sweep: mean judge score vs top_k\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fd20612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"sweep_summary\"):\n",
    "    mlflow.log_artifact(\"sweep_leaderboard.csv\")\n",
    "    plt.savefig(\"sweep_plot.png\", dpi=200, bbox_inches=\"tight\")\n",
    "    mlflow.log_artifact(\"sweep_plot.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
